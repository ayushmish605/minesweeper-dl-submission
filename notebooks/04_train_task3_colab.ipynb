{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 04 — Task 3 (Thinking Deeper)\n",
        "\n",
        "In this notebook, I implement **Task 3** for **all three difficulties**:\n",
        "\n",
        "- Easy (22×22, 50 mines)\n",
        "- Medium (22×22, 80 mines)\n",
        "- Hard (22×22, 100 mines)\n",
        "\n",
        "My core idea is to treat “thinking longer” as **running the same reasoning block more times** (a sequential computation / unrolling). Concretely, I reuse a shared Transformer-style block, and I let the model take more “internal steps” before it outputs a mine-probability map.\n",
        "\n",
        "What I’m trying to prove (per the PDF):\n",
        "- As I increase thinking steps, **the prediction loss goes down**.\n",
        "- As I increase thinking steps, **the gameplay performance goes up**.\n",
        "- The predicted mine heatmap changes in an interpretable way as I let the model think longer.\n",
        "\n",
        "Assumption: I already unzipped my project so the repo lives at `/content/repo/`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# I install the small deps I need for this notebook.\n",
        "# I avoid re-installing torch in Colab because checkpoint loading can get flaky\n",
        "# if the runtime's torch version changes mid-session.\n",
        "%pip install -q numpy tqdm matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# I locate my repo root so this notebook can import my code.\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "repo_root = Path('/content/repo')\n",
        "if not ((repo_root / 'minesweeper').exists() and (repo_root / 'models').exists()):\n",
        "    kids = [p for p in repo_root.iterdir() if p.is_dir()]\n",
        "    if len(kids) == 1:\n",
        "        repo_root = kids[0]\n",
        "\n",
        "if not ((repo_root / 'minesweeper').exists() and (repo_root / 'models').exists()):\n",
        "    raise FileNotFoundError(f'Bad repo_root: {repo_root}')\n",
        "\n",
        "sys.path.insert(0, str(repo_root))\n",
        "print('Repo root:', repo_root)\n",
        "\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1 — Load the Task 1 datasets (I reuse them for Task 3)\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "from models.dataset_cache import dataset_dir_for_task\n",
        "from models.task1 import load_task1_npz\n",
        "\n",
        "# I reuse the Task 1 `.npz`s because Task 3 uses the same dataset format.\n",
        "# I do this to avoid regenerating more data and to keep everything consistent.\n",
        "DATA_DIR = dataset_dir_for_task(repo_root=repo_root, task='task1')\n",
        "\n",
        "DIFFICULTIES = {\n",
        "    'easy': {'height': 22, 'width': 22, 'num_mines': 50},\n",
        "    'medium': {'height': 22, 'width': 22, 'num_mines': 80},\n",
        "    'hard': {'height': 22, 'width': 22, 'num_mines': 100},\n",
        "}\n",
        "\n",
        "datasets = {}\n",
        "for name in DIFFICULTIES.keys():\n",
        "    out_npz = DATA_DIR / f'task1_{name}_teacher_logic.npz'\n",
        "    if not out_npz.exists():\n",
        "        raise FileNotFoundError(\n",
        "            f\"Missing dataset: {out_npz}\\n\"\n",
        "            \"Run Notebook 02 first to generate the Task 1 datasets.\"\n",
        "        )\n",
        "\n",
        "    npz = load_task1_npz(out_npz)\n",
        "    meta = json.loads(npz.meta_json)\n",
        "    print(f\"{name}: samples={npz.x_visible.shape[0]} games={meta.get('num_games')}\")\n",
        "    datasets[name] = npz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2 — Train the \"thinking\" mine predictor\n",
        "from dataclasses import asdict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "from models.metrics import (\n",
        "    masked_bce_with_logits,\n",
        "    masked_binary_confusion_from_logits,\n",
        "    binary_metrics_from_confusion,\n",
        "    pos_weight_from_targets,\n",
        ")\n",
        "from models.task1.dataset import Task1Dataset\n",
        "from models.task3.model import ThinkingMinePredictor, ThinkingMinePredictorConfig\n",
        "\n",
        "\n",
        "def _add_conf(dst: dict, src: dict) -> None:\n",
        "    for k in ('tp', 'fp', 'tn', 'fn', 'n'):\n",
        "        dst[k] = int(dst.get(k, 0) or 0) + int(src.get(k, 0) or 0)\n",
        "\n",
        "\n",
        "def train_task3(\n",
        "    *,\n",
        "    npz,\n",
        "    cfg: ThinkingMinePredictorConfig,\n",
        "    run_name: str = \"\",\n",
        "    steps_train: int = 4,\n",
        "    epochs: int = 15,\n",
        "    batch_size: int = 64,\n",
        "    lr: float = 3e-4,\n",
        "    weight_decay: float = 1e-2,\n",
        "    val_frac: float = 0.1,\n",
        "    seed: int = 0,\n",
        "    threshold: float = 0.5,\n",
        "    use_pos_weight: bool = True,\n",
        "    early_stop_patience: int = 4,\n",
        "    early_stop_min_delta: float = 1e-4,\n",
        "):\n",
        "    # On A100/H100 (Ampere+), TF32 can speed up matmuls/conv a lot.\n",
        "    # PyTorch is deprecating the old allow_tf32 flags, so I use the new API with a fallback.\n",
        "    if torch.cuda.is_available():\n",
        "        try:\n",
        "            torch.backends.cuda.matmul.fp32_precision = 'tf32'\n",
        "        except Exception:\n",
        "            torch.backends.cuda.matmul.allow_tf32 = True\n",
        "        try:\n",
        "            torch.backends.cudnn.conv.fp32_precision = 'tf32'\n",
        "        except Exception:\n",
        "            torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "    ds = Task1Dataset(npz)\n",
        "\n",
        "    tag = (f\"[{str(run_name)}] \" if str(run_name) else \"\")\n",
        "    print(f\"{tag}train_task3: samples={len(ds)} steps_train={int(steps_train)} epochs={int(epochs)} batch_size={int(batch_size)} seed={int(seed)}\")\n",
        "\n",
        "    g = torch.Generator().manual_seed(int(seed))\n",
        "    perm = torch.randperm(len(ds), generator=g)\n",
        "    n_val = int(len(ds) * float(val_frac))\n",
        "    val_idx = perm[:n_val].tolist()\n",
        "    train_idx = perm[n_val:].tolist()\n",
        "\n",
        "    use_cuda = (device.type == 'cuda')\n",
        "\n",
        "    # On A100, I can usually push batch_size a bit higher, but Task 3 is heavier than Task 1.\n",
        "    # I bump it modestly to speed things up without risking OOM.\n",
        "    bs = int(batch_size)\n",
        "    if use_cuda:\n",
        "        try:\n",
        "            if 'A100' in torch.cuda.get_device_name(0):\n",
        "                bs = max(bs, 96)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # In Colab, DataLoader workers occasionally hang on me, so I keep `num_workers` small.\n",
        "    # If I want more throughput later, this is the first knob I try.\n",
        "    num_workers = 2 if use_cuda else 0\n",
        "    dl_common = dict(num_workers=int(num_workers), pin_memory=bool(use_cuda))\n",
        "    if int(num_workers) > 0:\n",
        "        dl_common['persistent_workers'] = True\n",
        "\n",
        "    train_loader = DataLoader(Subset(ds, train_idx), batch_size=int(bs), shuffle=True, **dl_common)\n",
        "    val_loader = DataLoader(Subset(ds, val_idx), batch_size=int(bs), shuffle=False, **dl_common)\n",
        "\n",
        "    model = ThinkingMinePredictor(cfg).to(device)\n",
        "\n",
        "    # I intentionally skip `torch.compile` here: on Colab I kept running into Dynamo/FakeTensor crashes\n",
        "    # (`DataDependentOutputException`). I'd rather have a boring run that finishes.\n",
        "\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=float(lr), weight_decay=float(weight_decay))\n",
        "\n",
        "    use_amp = bool(use_cuda)\n",
        "    scaler = (torch.amp.GradScaler('cuda') if use_amp else None)\n",
        "\n",
        "    best_f1 = -1.0\n",
        "    best_state = None\n",
        "    patience = 0\n",
        "\n",
        "    for epoch in range(1, int(epochs) + 1):\n",
        "        model.train()\n",
        "        tr = 0.0\n",
        "        tr_n = 0\n",
        "        tr_conf = {'tp': 0, 'fp': 0, 'tn': 0, 'fn': 0, 'n': 0}\n",
        "        for batch in train_loader:\n",
        "            x = batch['x'].to(device, non_blocking=use_cuda)\n",
        "            y = batch['y'].to(device, non_blocking=use_cuda)\n",
        "            m = batch['mask'].to(device, non_blocking=use_cuda)\n",
        "\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            with torch.amp.autocast(device_type=device.type, enabled=use_amp):\n",
        "                logits, per_step = model(x, steps=int(steps_train), return_all=True)\n",
        "\n",
        "                # Deep supervision: I compute loss at every internal think-step, and I weight later steps more.\n",
        "                # I normalize the weights so the total loss scale doesn't change with steps_train.\n",
        "                pw = pos_weight_from_targets(y, m) if bool(use_pos_weight) else None\n",
        "                denom = float(sum(range(1, int(len(per_step)) + 1)))\n",
        "                loss = torch.zeros((), device=device)\n",
        "                for i, li in enumerate(per_step, start=1):\n",
        "                    w = float(i) / denom\n",
        "                    loss = loss + w * masked_bce_with_logits(li, y, m, pos_weight=pw)\n",
        "\n",
        "            if scaler is not None:\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "\n",
        "            tr += float(loss.item())\n",
        "            tr_n += 1\n",
        "            _add_conf(tr_conf, masked_binary_confusion_from_logits(logits.detach(), y, m, threshold=float(threshold)))\n",
        "\n",
        "        model.eval()\n",
        "        va = 0.0\n",
        "        va_n = 0\n",
        "        va_conf = {'tp': 0, 'fp': 0, 'tn': 0, 'fn': 0, 'n': 0}\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                x = batch['x'].to(device, non_blocking=use_cuda)\n",
        "                y = batch['y'].to(device, non_blocking=use_cuda)\n",
        "                m = batch['mask'].to(device, non_blocking=use_cuda)\n",
        "                with torch.amp.autocast(device_type=device.type, enabled=use_amp):\n",
        "                    logits = model(x, steps=int(steps_train))\n",
        "                    pw = pos_weight_from_targets(y, m) if bool(use_pos_weight) else None\n",
        "                    vloss = masked_bce_with_logits(logits, y, m, pos_weight=pw)\n",
        "\n",
        "                va += float(vloss.item())\n",
        "                va_n += 1\n",
        "                _add_conf(va_conf, masked_binary_confusion_from_logits(logits, y, m, threshold=float(threshold)))\n",
        "\n",
        "        tr_m = binary_metrics_from_confusion(tr_conf['tp'], tr_conf['fp'], tr_conf['tn'], tr_conf['fn'])\n",
        "        va_m = binary_metrics_from_confusion(va_conf['tp'], va_conf['fp'], va_conf['tn'], va_conf['fn'])\n",
        "\n",
        "        print(\n",
        "            f\"{tag}epoch {epoch}/{epochs} | \"\n",
        "            f\"train loss {tr/max(1,tr_n):.4f} acc {tr_m['acc']:.3f} prec {tr_m['precision']:.3f} rec {tr_m['recall']:.3f} f1 {tr_m['f1']:.3f} | \"\n",
        "            f\"val loss {va/max(1,va_n):.4f} acc {va_m['acc']:.3f} prec {va_m['precision']:.3f} rec {va_m['recall']:.3f} f1 {va_m['f1']:.3f}\"\n",
        "        )\n",
        "\n",
        "        cur_f1 = float(va_m.get('f1', 0.0) or 0.0)\n",
        "        if cur_f1 > (best_f1 + float(early_stop_min_delta)):\n",
        "            best_f1 = cur_f1\n",
        "            best_state = {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
        "            patience = 0\n",
        "        else:\n",
        "            patience += 1\n",
        "            if patience >= int(early_stop_patience):\n",
        "                print(f'early stop: no val f1 improvement for {early_stop_patience} epoch(s). best_f1={best_f1:.4f}')\n",
        "                break\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# I train + save one model per difficulty.\n",
        "CKPT_DIR = Path(repo_root) / 'models' / 'task3' / 'checkpoints'\n",
        "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# I append a version tag to my Task 3 checkpoints the same way I did for Task 2 runs.\n",
        "# I keep the tag short so I can store multiple experiments side-by-side.\n",
        "CKPT_TAG = 'v2_longer_train_ci'  # longer training + thinking-time eval + CIs + figure export\n",
        "\n",
        "# I keep an explicit overwrite flag so reruns don't silently destroy checkpoints.\n",
        "OVERWRITE = False\n",
        "\n",
        "# In Colab, TorchDynamo/FakeTensor can crash on me even when I don't need compilation.\n",
        "# I hard-disable Dynamo so training runs eagerly and reliably.\n",
        "try:\n",
        "    import torch._dynamo as _dynamo\n",
        "\n",
        "    _dynamo.config.disable = True\n",
        "    _dynamo.config.suppress_errors = True\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "EPOCHS_BY_DIFF = {\n",
        "    # Easy is already strong, but in my run the val metrics were still improving at epoch 15, so I let it go longer.\n",
        "    'easy': 25,\n",
        "    # Medium/hard usually need more optimization steps to converge.\n",
        "    'medium': 35,\n",
        "    'hard': 40,\n",
        "}\n",
        "\n",
        "TRAINING_CFG = dict(\n",
        "    # I set epochs per difficulty via EPOCHS_BY_DIFF.\n",
        "    batch_size=64,\n",
        "    lr=3e-4,\n",
        "    weight_decay=1e-2,\n",
        "    val_frac=0.1,\n",
        "    seed=0,\n",
        "    early_stop_patience=6,\n",
        ")\n",
        "\n",
        "trained = {}\n",
        "for name, diff in DIFFICULTIES.items():\n",
        "    ckpt_path = CKPT_DIR / f'task3_{name}_{CKPT_TAG}.pt'\n",
        "\n",
        "    if (not bool(OVERWRITE)) and ckpt_path.exists():\n",
        "        print(f\"Skipping {name}: checkpoint already exists -> {ckpt_path}\")\n",
        "        trained[name] = str(ckpt_path)\n",
        "        continue\n",
        "\n",
        "    npz = datasets[name]\n",
        "    cfg = ThinkingMinePredictorConfig(height=int(diff['height']), width=int(diff['width']), default_steps=4)\n",
        "    print(f\"\\nTraining Task 3 model for {name}...\")\n",
        "    epochs_here = int(EPOCHS_BY_DIFF.get(str(name), 25))\n",
        "    model = train_task3(npz=npz, cfg=cfg, run_name=str(name), steps_train=4, epochs=epochs_here, **TRAINING_CFG)\n",
        "\n",
        "    meta = json.loads(npz.meta_json)\n",
        "\n",
        "    torch.save(\n",
        "        {\n",
        "            'task': 'task3_thinking_deeper',\n",
        "            'difficulty': name,\n",
        "            'difficulty_cfg': diff,\n",
        "            'checkpoint_tag': str(CKPT_TAG),\n",
        "            'dataset_meta': meta,\n",
        "            'model_cfg': asdict(cfg),\n",
        "            'state_dict': model.state_dict(),\n",
        "        },\n",
        "        ckpt_path,\n",
        "    )\n",
        "\n",
        "    # I also save a convenience copy for the GUI (unversioned name).\n",
        "    # If I want to keep multiple versions side-by-side, I load the tagged file.\n",
        "    try:\n",
        "        torch.save(\n",
        "            {\n",
        "                'task': 'task3_thinking_deeper',\n",
        "                'difficulty': name,\n",
        "                'difficulty_cfg': diff,\n",
        "                'checkpoint_tag': str(CKPT_TAG),\n",
        "                'dataset_meta': meta,\n",
        "                'model_cfg': asdict(cfg),\n",
        "                'state_dict': model.state_dict(),\n",
        "            },\n",
        "            CKPT_DIR / f'task3_{name}.pt',\n",
        "        )\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    print(f\"Saved {name} -> {ckpt_path}\")\n",
        "    trained[name] = str(ckpt_path)\n",
        "\n",
        "trained\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3 — I show that more thinking helps (loss vs steps)\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "from models.metrics import masked_bce_with_logits\n",
        "from models.task1.dataset import Task1Dataset\n",
        "from models.task3.model import ThinkingMinePredictor, ThinkingMinePredictorConfig\n",
        "\n",
        "EVAL_NAME = 'medium'  # 'easy' | 'medium' | 'hard'\n",
        "EVAL_CFG = DIFFICULTIES[EVAL_NAME]\n",
        "EVAL_NPZ = datasets[EVAL_NAME]\n",
        "\n",
        "ckpt_path = Path(repo_root) / 'models' / 'task3' / 'checkpoints' / f'task3_{EVAL_NAME}_{CKPT_TAG}.pt'\n",
        "if not ckpt_path.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Missing checkpoint: {ckpt_path}\\n\"\n",
        "        \"Run Step 2 first to train the v2 checkpoints (or change CKPT_TAG).\"\n",
        "    )\n",
        "\n",
        "ckpt = torch.load(ckpt_path, map_location=device)\n",
        "mcfg = ckpt.get('model_cfg') or {'height': int(EVAL_CFG['height']), 'width': int(EVAL_CFG['width']), 'default_steps': 4}\n",
        "model = ThinkingMinePredictor(ThinkingMinePredictorConfig(**mcfg)).to(device)\n",
        "model.load_state_dict(ckpt['state_dict'])\n",
        "model.eval()\n",
        "\n",
        "# I measure validation loss at different thinking depths.\n",
        "# I treat this as a quick sanity check (not a careful statistical estimate).\n",
        "# I keep it deterministic so when I re-run later, I'm comparing apples to apples.\n",
        "\n",
        "def eval_loss_for_steps(steps: int, n_batches: int = 20, seed: int = 0) -> float:\n",
        "    ds = Task1Dataset(EVAL_NPZ)\n",
        "\n",
        "    # I fixed subset for stable comparisons.\n",
        "    g = torch.Generator().manual_seed(int(seed))\n",
        "    idx = torch.randperm(len(ds), generator=g)[: int(64 * n_batches)].tolist()\n",
        "    sub = Subset(ds, idx)\n",
        "\n",
        "    use_cuda = (device.type == 'cuda')\n",
        "    loader = DataLoader(sub, batch_size=64, shuffle=False, num_workers=0, pin_memory=bool(use_cuda))\n",
        "\n",
        "    total = 0.0\n",
        "    count = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            x = batch['x'].to(device, non_blocking=use_cuda)\n",
        "            y = batch['y'].to(device, non_blocking=use_cuda)\n",
        "            m = batch['mask'].to(device, non_blocking=use_cuda)\n",
        "            with torch.amp.autocast(device_type=device.type, enabled=use_cuda):\n",
        "                logits = model(x, steps=int(steps))\n",
        "                total += float(masked_bce_with_logits(logits, y, m).item())\n",
        "            count += 1\n",
        "            if count >= int(n_batches):\n",
        "                break\n",
        "    return total / max(1, count)\n",
        "\n",
        "steps_list = [1, 2, 4, 6, 8]\n",
        "losses = [eval_loss_for_steps(s) for s in steps_list]\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(steps_list, losses, marker='o')\n",
        "plt.xlabel('thinking steps')\n",
        "plt.ylabel('masked BCE loss (approx)')\n",
        "plt.title(f'Task 3 ({EVAL_NAME}): loss vs thinking steps')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print('loss vs steps:')\n",
        "for s, l in zip(steps_list, losses):\n",
        "    print(f'  steps={s:>2d}  loss={l:.6f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4 — I evaluate gameplay: does the bot improve when I let it think longer?\n",
        "import numpy as np\n",
        "\n",
        "from minesweeper.game import MinesweeperGame, GameState\n",
        "from models.task3.policy import select_safest_unrevealed_thinking\n",
        "\n",
        "\n",
        "def play_one_game(*, diff: dict, model: ThinkingMinePredictor, steps: int, seed: int, max_steps: int = 512) -> dict:\n",
        "    # I keep first-click selection deterministic per seed so I can compare steps fairly.\n",
        "    rng = np.random.default_rng(int(seed))\n",
        "    first_r = int(rng.integers(0, int(diff['height'])))\n",
        "    first_c = int(rng.integers(0, int(diff['width'])))\n",
        "\n",
        "    g = MinesweeperGame(height=int(diff['height']), width=int(diff['width']), num_mines=int(diff['num_mines']), seed=int(seed))\n",
        "    buttons_clear = set()\n",
        "    g.player_clicks(first_r, first_c, buttons_clear)\n",
        "\n",
        "    n = 0\n",
        "    while g.get_game_state() == GameState.PROG and n < int(max_steps):\n",
        "        a = select_safest_unrevealed_thinking(\n",
        "            model,\n",
        "            g.get_visible_board(),\n",
        "            device=device,\n",
        "            steps=int(steps),\n",
        "            temperature=1.0,\n",
        "        )\n",
        "        if a is None:\n",
        "            break\n",
        "        buttons_clear = set()\n",
        "        g.player_clicks(int(a[0]), int(a[1]), buttons_clear)\n",
        "        n += 1\n",
        "\n",
        "    st = g.get_statistics()\n",
        "    return {\n",
        "        'won': bool(st['game_won']) and (int(st['mines_triggered']) == 0),\n",
        "        'cells_opened': int(st['cells_opened']),\n",
        "        'mines_triggered': int(st['mines_triggered']),\n",
        "    }\n",
        "\n",
        "\n",
        "def eval_play_vs_steps(*, diff: dict, model: ThinkingMinePredictor, steps_list: list[int], n_games: int = 60, seed0: int = 0) -> dict:\n",
        "    out = {}\n",
        "    seeds = [int(seed0) + i for i in range(int(n_games))]\n",
        "\n",
        "    for s in steps_list:\n",
        "        wins = 0\n",
        "        mines = 0\n",
        "        opened = 0\n",
        "        for seed in seeds:\n",
        "            r = play_one_game(diff=diff, model=model, steps=int(s), seed=int(seed))\n",
        "            wins += int(r['won'])\n",
        "            mines += int(r['mines_triggered'])\n",
        "            opened += int(r['cells_opened'])\n",
        "\n",
        "        out[int(s)] = {\n",
        "            'n': int(n_games),\n",
        "            'win_rate': float(wins) / float(max(1, n_games)),\n",
        "            'avg_mines_triggered': float(mines) / float(max(1, n_games)),\n",
        "            'avg_cells_opened': float(opened) / float(max(1, n_games)),\n",
        "        }\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "# I evaluate all steps on the same seeds so the comparison is fair.\n",
        "# I keep this lightweight by only bootstrapping a CI for win rate.\n",
        "\n",
        "def bootstrap_mean_ci(x: np.ndarray, *, n_boot: int = 2000, alpha: float = 0.05, seed: int = 0) -> tuple[float, float, float]:\n",
        "    x = np.asarray(x, dtype=np.float64)\n",
        "    if x.size == 0:\n",
        "        return (float('nan'), float('nan'), float('nan'))\n",
        "\n",
        "    rng = np.random.default_rng(int(seed))\n",
        "    n = int(x.size)\n",
        "    means = []\n",
        "    for _ in range(int(n_boot)):\n",
        "        idx = rng.integers(0, n, size=n)\n",
        "        means.append(float(np.mean(x[idx])))\n",
        "    means = np.asarray(means, dtype=np.float64)\n",
        "\n",
        "    lo = float(np.quantile(means, float(alpha) / 2.0))\n",
        "    hi = float(np.quantile(means, 1.0 - float(alpha) / 2.0))\n",
        "    return (float(np.mean(x)), lo, hi)\n",
        "\n",
        "\n",
        "def eval_play_vs_steps_with_ci(*, diff: dict, model: ThinkingMinePredictor, steps_list: list[int], n_games: int = 60, seed0: int = 0) -> dict:\n",
        "    out = {}\n",
        "    seeds = [int(seed0) + i for i in range(int(n_games))]\n",
        "\n",
        "    for s in steps_list:\n",
        "        wins = []\n",
        "        mines = []\n",
        "        opened = []\n",
        "        for seed in seeds:\n",
        "            r = play_one_game(diff=diff, model=model, steps=int(s), seed=int(seed))\n",
        "            wins.append(int(r['won']))\n",
        "            mines.append(int(r['mines_triggered']))\n",
        "            opened.append(int(r['cells_opened']))\n",
        "\n",
        "        wins = np.asarray(wins, dtype=np.float64)\n",
        "        mines = np.asarray(mines, dtype=np.float64)\n",
        "        opened = np.asarray(opened, dtype=np.float64)\n",
        "\n",
        "        mu, lo, hi = bootstrap_mean_ci(wins, seed=int(seed0) + 999 + int(s))\n",
        "\n",
        "        out[int(s)] = {\n",
        "            'n': int(n_games),\n",
        "            'win_rate': float(mu),\n",
        "            'win_ci_lo': float(lo),\n",
        "            'win_ci_hi': float(hi),\n",
        "            'avg_mines_triggered': float(np.mean(mines)),\n",
        "            'avg_cells_opened': float(np.mean(opened)),\n",
        "        }\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "PLAY_N = 60\n",
        "play = eval_play_vs_steps_with_ci(diff=EVAL_CFG, model=model, steps_list=steps_list, n_games=int(PLAY_N), seed0=123)\n",
        "\n",
        "print('\\nTask 3 gameplay vs thinking steps (same seeds; deterministic first click per seed)')\n",
        "for s in steps_list:\n",
        "    d = play[int(s)]\n",
        "    print(\n",
        "        f\"  steps={s:>2d} | win_rate={d['win_rate']:.3f} \"\n",
        "        f\"(95% CI {d['win_ci_lo']:.3f}..{d['win_ci_hi']:.3f}) | \"\n",
        "        f\"avg_mines={d['avg_mines_triggered']:.3f} | avg_opened={d['avg_cells_opened']:.1f}\"\n",
        "    )\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "x = np.asarray(steps_list, dtype=np.float64)\n",
        "y = np.asarray([play[int(s)]['win_rate'] for s in steps_list], dtype=np.float64)\n",
        "ylo = np.asarray([play[int(s)]['win_rate'] - play[int(s)]['win_ci_lo'] for s in steps_list], dtype=np.float64)\n",
        "yhi = np.asarray([play[int(s)]['win_ci_hi'] - play[int(s)]['win_rate'] for s in steps_list], dtype=np.float64)\n",
        "\n",
        "plt.errorbar(x, y, yerr=[ylo, yhi], marker='o', capsize=3)\n",
        "plt.xlabel('thinking steps')\n",
        "plt.ylabel('perfect win rate (clear with 0 mines)')\n",
        "plt.title(f'Task 3 ({EVAL_NAME}): win rate vs thinking steps')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5 — I plot heatmap evolution (required figure)\n",
        "# Here I take one fixed partially-revealed board and show how mine probabilities change as I let the model think longer.\n",
        "\n",
        "# I pick one fixed sample board so the per-step heatmaps are directly comparable.\n",
        "sample = Task1Dataset(EVAL_NPZ)[0]\n",
        "x0 = sample['x'].unsqueeze(0).to(device)\n",
        "final_logits, per_step = model(x0, steps=8, return_all=True)\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(14, 7))\n",
        "axes = axes.reshape(-1)\n",
        "for i in range(8):\n",
        "    probs = torch.sigmoid(per_step[i]).squeeze(0).detach().cpu().numpy()\n",
        "    ax = axes[i]\n",
        "    im = ax.imshow(probs, vmin=0.0, vmax=1.0, cmap='viridis')\n",
        "    ax.set_title(f'step {i+1}')\n",
        "    ax.axis('off')\n",
        "fig.colorbar(im, ax=axes.tolist(), fraction=0.02, pad=0.02)\n",
        "plt.suptitle(f'Mine probability heatmap as I think longer ({EVAL_NAME})')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 6 — I save the figures + JSON summaries into docs/figures\n",
        "# I export JSON so I can re-plot in Notebook 05 without copy/pasting logs, and I export PNGs\n",
        "# so I can drop the figures directly into my writeup.\n",
        "\n",
        "import json\n",
        "\n",
        "fig_dir = Path(repo_root) / 'docs' / 'figures'\n",
        "fig_dir.mkdir(parents=True, exist_ok=True)\n",
        "print('Figure dir:', fig_dir)\n",
        "\n",
        "# I save loss vs steps\n",
        "out_loss = {\n",
        "    'difficulty': str(EVAL_NAME),\n",
        "    'steps_list': [int(s) for s in steps_list],\n",
        "    'losses': [float(x) for x in losses],\n",
        "}\n",
        "loss_json = fig_dir / f'task3_{EVAL_NAME}_loss_vs_steps.json'\n",
        "loss_png = fig_dir / f'task3_{EVAL_NAME}_loss_vs_steps.png'\n",
        "\n",
        "with open(loss_json, 'w') as f:\n",
        "    json.dump(out_loss, f, indent=2)\n",
        "print('wrote', loss_json)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(steps_list, losses, marker='o')\n",
        "plt.xlabel('thinking steps')\n",
        "plt.ylabel('masked BCE loss (approx)')\n",
        "plt.title(f'Task 3 ({EVAL_NAME}): loss vs thinking steps')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(loss_png, dpi=200)\n",
        "plt.close()\n",
        "print('wrote', loss_png)\n",
        "\n",
        "# I save gameplay vs steps\n",
        "play_json = fig_dir / f'task3_{EVAL_NAME}_play_vs_steps.json'\n",
        "play_png = fig_dir / f'task3_{EVAL_NAME}_win_rate_vs_steps.png'\n",
        "\n",
        "with open(play_json, 'w') as f:\n",
        "    json.dump({'difficulty': str(EVAL_NAME), 'by_steps': play}, f, indent=2)\n",
        "print('wrote', play_json)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "x = np.asarray(steps_list, dtype=np.float64)\n",
        "y = np.asarray([play[int(s)]['win_rate'] for s in steps_list], dtype=np.float64)\n",
        "ylo = np.asarray([play[int(s)]['win_rate'] - play[int(s)]['win_ci_lo'] for s in steps_list], dtype=np.float64)\n",
        "yhi = np.asarray([play[int(s)]['win_ci_hi'] - play[int(s)]['win_rate'] for s in steps_list], dtype=np.float64)\n",
        "plt.errorbar(x, y, yerr=[ylo, yhi], marker='o', capsize=3)\n",
        "plt.xlabel('thinking steps')\n",
        "plt.ylabel('perfect win rate (clear with 0 mines)')\n",
        "plt.title(f'Task 3 ({EVAL_NAME}): win rate vs thinking steps')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(play_png, dpi=200)\n",
        "plt.close()\n",
        "print('wrote', play_png)\n",
        "\n",
        "# I save the heatmap grid\n",
        "heat_png = fig_dir / f'task3_{EVAL_NAME}_heatmaps_steps_1_to_8.png'\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(14, 7))\n",
        "axes = axes.reshape(-1)\n",
        "for i in range(8):\n",
        "    probs = torch.sigmoid(per_step[i]).squeeze(0).detach().cpu().numpy()\n",
        "    ax = axes[i]\n",
        "    im = ax.imshow(probs, vmin=0.0, vmax=1.0, cmap='viridis')\n",
        "    ax.set_title(f'step {i+1}')\n",
        "    ax.axis('off')\n",
        "fig.colorbar(im, ax=axes.tolist(), fraction=0.02, pad=0.02)\n",
        "fig.suptitle(f'Task 3 ({EVAL_NAME}): heatmaps as I let the model think longer')\n",
        "fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "fig.savefig(heat_png, dpi=200)\n",
        "plt.close(fig)\n",
        "print('wrote', heat_png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (Optional) After training, I immediately export a zip so I don't lose checkpoints if Colab disconnects.\n",
        "# I run this right after Step 2 finishes.\n",
        "\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "\n",
        "bundle_dir = Path('/content')\n",
        "zip_out = bundle_dir / 'task3_artifacts.zip'\n",
        "\n",
        "paths_to_bundle = [\n",
        "    Path(repo_root) / 'models' / 'task3' / 'checkpoints',\n",
        "    Path(repo_root) / 'docs' / 'figures',\n",
        "]\n",
        "\n",
        "if zip_out.exists():\n",
        "    zip_out.unlink()\n",
        "\n",
        "with zipfile.ZipFile(zip_out, 'w', compression=zipfile.ZIP_DEFLATED) as z:\n",
        "    for root in paths_to_bundle:\n",
        "        if not root.exists():\n",
        "            continue\n",
        "        for p in root.rglob('*'):\n",
        "            if p.is_dir():\n",
        "                continue\n",
        "            rel = p.relative_to(Path(repo_root))\n",
        "            z.write(p, arcname=str(rel))\n",
        "\n",
        "mb = zip_out.stat().st_size / (1024 * 1024)\n",
        "print(f'Wrote: {zip_out} ({mb:.2f} MB)')\n",
        "print('In Colab: use the Files panel to download task3_artifacts.zip')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
